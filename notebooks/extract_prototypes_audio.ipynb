{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../')\n",
    "from apnet.model import APNet\n",
    "from apnet.layers import PrototypeLayer, WeightedSum\n",
    "from apnet.datasets import MedleySolosDb, GoogleSpeechCommands\n",
    "\n",
    "from dcase_models.data.datasets import UrbanSound8k\n",
    "from dcase_models.data.features import MelSpectrogram\n",
    "from dcase_models.util.files import load_json, mkdir_if_not_exists\n",
    "from dcase_models.util.files import load_pickle, save_pickle\n",
    "from dcase_models.data.data_generator import DataGenerator\n",
    "from dcase_models.data.scaler import Scaler\n",
    "from dcase_models.util.data import evaluation_setup\n",
    "\n",
    "from dcase_models.util.files import mkdir_if_not_exists, list_wav_files\n",
    "\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'UrbanSound8k': UrbanSound8k,\n",
    "    'MedleySolosDb': MedleySolosDb,\n",
    "    'GoogleSpeechCommands': GoogleSpeechCommands,    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'APNet'\n",
    "features_name = 'MelSpectrogram'\n",
    "\n",
    "dataset_name = 'GoogleSpeechCommands' #'MedleySolosDb' #'UrbanSound8k'\n",
    "fold_name = 'test' #'fold10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get parameters\n",
    "exp_path = '../experiments'\n",
    "model_folder = os.path.join(exp_path, dataset_name, model_name)\n",
    "parameters_file = os.path.join(model_folder, 'config.json')\n",
    "params = load_json(parameters_file)\n",
    "params_dataset = params['datasets'][dataset_name]\n",
    "params_features = params['features'][features_name]\n",
    "params_model = params['models']['APNet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = os.path.join(exp_path, params_dataset['dataset_path'])\n",
    "dataset = datasets[dataset_name](dataset_path)\n",
    "dataset.check_if_downloaded()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 60, 80)\n"
     ]
    }
   ],
   "source": [
    "features = MelSpectrogram(**params_features)\n",
    "print(features.get_shape())\n",
    "if not features.check_if_extracted(dataset):\n",
    "    features.extract(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105, 20)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 60, 80)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Model)                 [(None, 15, 20, 48), 116544      input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "features (Lambda)               (None, 15, 20, 48)   0           encoder[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "prototype_distances (PrototypeL (None, 105, 20)      1512000     features[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "similarity_local (Lambda)       (None, 105, 20)      0           prototype_distances[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "mean (WeightedSum)              (None, 105)          2100        similarity_local[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "logits (Dense)                  (None, 35)           3675        mean[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "out (Activation)                (None, 35)           0           logits[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Model)                 (None, 60, 80)       116497      encoder[1][0]                    \n",
      "                                                                 encoder[1][1]                    \n",
      "                                                                 encoder[1][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 105, 20)      0           prototype_distances[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 1,750,816\n",
      "Trainable params: 1,750,816\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "exp_folder = os.path.join(model_folder, fold_name)\n",
    "scaler = load_pickle(os.path.join(exp_folder, 'scaler.pickle'))\n",
    "\n",
    "model_container = APNet(\n",
    "    model=None, model_path=exp_folder, \n",
    "    custom_objects={\n",
    "        'PrototypeLayer': PrototypeLayer,\n",
    "        'WeightedSum': WeightedSum\n",
    "    },\n",
    "    **params['models']['APNet']['model_arguments']\n",
    ")\n",
    "model_container.load_model_weights(exp_folder)\n",
    "model_container.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_train, folds_val, _ = evaluation_setup(\n",
    "    fold_name, dataset.fold_list,\n",
    "    params_dataset['evaluation_mode'],\n",
    "    use_validate_set=True\n",
    ")\n",
    "data_gen_train = DataGenerator(\n",
    "    dataset, features, folds=folds_train,\n",
    "    batch_size=params['train']['batch_size'],\n",
    "    shuffle=True, train=True, scaler=scaler\n",
    ")\n",
    "\n",
    "if dataset_name in ['MedleySolosDb', 'GoogleSpeechCommands']:\n",
    "    data_gen_train.audio_file_list = data_gen_train.audio_file_list[:int(len( data_gen_train.audio_file_list)/3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28281, 60, 80) (28281, 35)\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train = data_gen_train.get_data()\n",
    "print(X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting prototypes (spectrograms)...\n",
      "Done!\n",
      "Converting to audio...\n",
      "[############################################################] 105/105\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#model_container.prototypes = load_pickle(os.path.join(exp_folder, 'prototypes.pickle'))\n",
    "\n",
    "convert_audio_params = {\n",
    "    'sr': params_features['sr'],\n",
    "    'scaler': scaler,\n",
    "    'mel_basis': features.mel_basis,\n",
    "    'audio_hop': params_features['audio_hop'],\n",
    "    'audio_win': params_features['audio_win']\n",
    "}\n",
    "\n",
    "model_container.get_prototypes(X_train, convert_audio_params=convert_audio_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_container.prototypes.sort()\n",
    "\n",
    "prototypes_folder = os.path.join('../prototypes', dataset_name)\n",
    "mkdir_if_not_exists(prototypes_folder, parents=True)\n",
    "\n",
    "for j, audio_dict in enumerate(model_container.prototypes.audios):\n",
    "    class_name = dataset.label_list[model_container.prototypes.classes[j]]\n",
    "    if dataset_name == 'GoogleSpeechCommands':\n",
    "        file_name = '%03d_%s.wav' % (j, class_name)\n",
    "    else:\n",
    "        file_name = '%02d_%s.wav' % (j, class_name)\n",
    "    file_path = os.path.join(prototypes_folder, file_name)\n",
    "    sf.write(file_path, audio_dict['data']/np.amax(audio_dict['data']), audio_dict['sr']) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
